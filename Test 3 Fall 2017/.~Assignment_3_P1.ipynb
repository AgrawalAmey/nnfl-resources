{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e74ca2dfb04d2ebe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jdc==0.0.5 from file:///home/nbuser/library/jdc-0.0.5-py2.py3-none-any.whl in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "! pip install jdc-0.0.5-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ff93142d7cb0b0c3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import numpy as np\n",
    "import jdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a206ea2c1ad08e8e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We define a generic neural network architecture as a python class which we would use in multiple exercies. You might want to revisit the tutorial notebook for a quick refresher on python classes.\n",
    "\n",
    "**Note:** We are using jdc to define each method of `class Network` in seperate cells. jdc follows the following syntax,\n",
    "\n",
    "```py\n",
    "%%add_to #CLASS_NAME#\n",
    "def dummy_method(self):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04821d40c8886c90",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Question 1\n",
    "\n",
    "## Design an XOR gate using a Neural Network\n",
    "\n",
    "A Perceptron can only be employed in the case of linearly separable data like the truth tables of AND and OR gates. The XOR gate truth table on the other hand, is not linearly separable and the figure below illustrates why.\n",
    "![](https://qph.ec.quoracdn.net/main-qimg-a6c557af4280d1f85cacc66e048e82f3)\n",
    "\n",
    "This is where a Multi-Layer Perceptron is used. The following figure is a representaion of the network used to design an XOR gate. All sub-parts to this question will be based on this partiular architecture.  \n",
    "![](https://i.stack.imgur.com/wd0Q1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b87b6d22bfdfec95",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<a id = 'questions'></a>\n",
    "**The question contains 5 sub-parts. There are dependencies between functions which might change the way how functions work.**  \n",
    "\n",
    "<a href = '#section1'> Q1.1.</a> Complete the code for **'ReLU'** activation function and its derivative **'ReLU_derivative'**.        **3 marks**  \n",
    "<a href = '#section2'> Q1.2.</a> Incorporate the momentum term in the expression for weight update in the function **'update_params'**.           **5 marks**   \n",
    "<a href = '#section3'> Q1.3.</a> Implement L2 regularization (will be explained later) by making necessary modifications to the functions **'loss_L2reg'** and **'update_param'**.  **4 marks**   \n",
    "<a href = '#section4'> Q1.4.</a> Complete the code for function **'backward'**.   **5 marks**    \n",
    "<a href = '#section5'> Q1.5.</a> Train your network for the above-mentioned architecture   **3 marks** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57f92cbadbcd3153",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },